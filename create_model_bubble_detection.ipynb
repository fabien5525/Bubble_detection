{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sep = os.sep\n",
    "\n",
    "images_paths = []\n",
    "labels_paths = []\n",
    "\n",
    "raw_data_path = 'raw_data'\n",
    "raw_data_valid_path = 'raw_data_valid'\n",
    "\n",
    "# Create dataset/train with raw_data\n",
    "for name in os.listdir(raw_data_path):\n",
    "    for chapter in os.listdir(raw_data_path + sep + name):\n",
    "        if os.path.exists(raw_data_path + sep + name + sep + chapter + sep + 'obj_train_data'):\n",
    "            for image in os.listdir(raw_data_path + sep + name + sep + chapter + sep + 'obj_train_data'):\n",
    "                images_paths.append(raw_data_path + sep + name + sep + chapter + sep + 'obj_train_data' + sep + image)\n",
    "                labels_paths.append(raw_data_path + sep + name + sep + chapter + sep + 'obj_train_data' + sep + image.replace('.jpg', '.txt'))\n",
    "\n",
    "images = pd.DataFrame(images_paths)\n",
    "labels = pd.DataFrame(labels_paths)\n",
    "\n",
    "images_paths_test = []\n",
    "labels_paths_test = []\n",
    "\n",
    "# Create dataset/test with raw_data_valid\n",
    "for name in os.listdir(raw_data_valid_path):\n",
    "    for chapter in os.listdir(raw_data_valid_path + sep + name):\n",
    "        if os.path.exists(raw_data_valid_path + sep + name + sep + chapter + sep + 'obj_train_data'):\n",
    "            for image in os.listdir(raw_data_valid_path + sep + name + sep + chapter + sep + 'obj_train_data'):\n",
    "                images_paths_test.append(raw_data_valid_path + sep + name + sep + chapter + sep + 'obj_train_data' + sep + image)\n",
    "                labels_paths_test.append(raw_data_valid_path + sep + name + sep + chapter + sep + 'obj_train_data' + sep + image.replace('.jpg', '.txt'))\n",
    "\n",
    "images_test = pd.DataFrame(images_paths_test)\n",
    "labels_test = pd.DataFrame(labels_paths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(images_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data structure like this\n",
    "\n",
    "# ├── train\n",
    "# │   ├── images\n",
    "# │   ├── labels\n",
    "# ├── valid\n",
    "# │   ├── images\n",
    "# │   ├── labels\n",
    "# └── data.yaml\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "sep = os.sep\n",
    "datasetPath = 'dataset' + sep\n",
    "trainPath = datasetPath + 'train'\n",
    "validPath = datasetPath + 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old data\n",
    "shutil.rmtree('dataset', ignore_errors=True)\n",
    "\n",
    "# Create new dataset\n",
    "\n",
    "## Create dataset folders\n",
    "os.system('mkdir dataset')\n",
    "\n",
    "os.system('mkdir ' + trainPath)\n",
    "os.system('mkdir ' + trainPath + sep +'images')\n",
    "os.system('mkdir ' + trainPath + sep +'labels')\n",
    "\n",
    "os.system('mkdir ' + validPath)\n",
    "os.system('mkdir ' + validPath + sep +'images')\n",
    "os.system('mkdir ' + validPath + sep +'labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Training images and labels to train folder and same for validation images and labels\n",
    "\n",
    "if (len(images) != len(labels) or len(images_test) != len(labels_test)):\n",
    "    print('Error: images and labels must have the same length')\n",
    "    exit()\n",
    "\n",
    "for i in range(len(images)):\n",
    "\n",
    "    if (i % 2 != 0):\n",
    "        continue\n",
    "\n",
    "    filePath = images[0][i]\n",
    "    filePathTxt = labels[0][i]\n",
    "    name = filePath.split(sep)[-4]\n",
    "    chapter = filePath.split(sep)[-3]\n",
    "    num = filePath.split(sep)[-1].split('.')[0]\n",
    "    newName = name + '_' + chapter + '_' + num\n",
    "    newName = newName.replace(' ', '')\n",
    "\n",
    "    ti = datasetPath + 'train' + sep + 'images' + sep + newName + '.jpg';\n",
    "    tl = datasetPath + 'train' + sep + 'labels' + sep + newName + '.txt';\n",
    "    tlc = datasetPath + 'train' + sep + 'labels.cache' + sep + newName + '.txt';\n",
    "\n",
    "    shutil.copy(filePath, ti)\n",
    "    shutil.copy(filePathTxt, tl)\n",
    "\n",
    "for i in range(len(images_test)):\n",
    "\n",
    "    if (i % 2 != 0):\n",
    "        continue\n",
    "    \n",
    "    filePath = images_test[0][i]\n",
    "    filePathTxt = labels_test[0][i]\n",
    "    name = filePath.split(sep)[-4]\n",
    "    chapter = filePath.split(sep)[-3]\n",
    "    num = filePath.split(sep)[-1].split('.')[0]\n",
    "    newName = name + '_' + chapter + '_' + num\n",
    "    newName = newName.replace(' ', '')\n",
    "\n",
    "    ti = datasetPath + 'valid' + sep + 'images' + sep + newName + '.jpg';\n",
    "    tl = datasetPath + 'valid' + sep + 'labels' + sep + newName + '.txt';\n",
    "    tlc = datasetPath + 'valid' + sep + 'labels.cache' + sep + newName + '.txt';\n",
    "\n",
    "    shutil.copy(filePath, ti)\n",
    "    shutil.copy(filePathTxt, tl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as glob\n",
    "import time\n",
    "\t\n",
    "if not os.path.exists('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5.git\n",
    "\n",
    "%cd yolov5\n",
    "    \n",
    "TRAIN = True\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "timestamp = str(int(time.time()))\n",
    "RES_DIR = '..' + sep + '..' + sep + '..' + sep + '..' + sep + 'results' + sep + 'result_' + timestamp\n",
    "DATA_YAML_PATH = '..' + sep + 'data.yaml'\n",
    "print(\"to run in local :\", \"python train.py --data \" + DATA_YAML_PATH + \" --weights yolov5s.pt --img 640 --epochs \" + str(EPOCHS) + \" --batch-size \" + str(BATCH_SIZE) + \" --name \" + RES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data {DATA_YAML_PATH} --weights yolov5s.pt --img 640 --epochs {EPOCHS} --batch-size {BATCH_SIZE} --name {RES_DIR}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
